{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Product Recommendation: Data Wrangling/Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I decided to go with the [Santander Product Recommendation Kaggle competition](https://www.kaggle.com/c/santander-product-recommendation). By doing so, it makes the data wrangling process fairly straightforward. All that needed to be done to acquire the data was downloading the zip file associated with the competition. It included 3 csv files: A training dataset, a testing dataset and a sample submission. For now, I will only be using the training dataset.\n",
    "\n",
    "Since the data was pretty much wrangled for me, I will use this notebook mostly for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,8,10,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "#Limit rows to 7 million\n",
    "df = pd.read_csv('Data/train_ver2.csv', nrows=7000000, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is very large. If I were to keep it at 7 million rows, speed would suffer significantly. Therefore, I will take a random sample of those 7 million and keep the dataset at 1 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a random sample of 1 million\n",
    "df = df.sample(1000000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to rename the columns, because they are mostly in Spanish. I decided to do this so that I could keep things easy to understand and follow along with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "df.columns = ['date', 'customer_code', 'employee_index', 'customer_country', 'sex', 'age', 'first_contract_date', \n",
    "              'new_customer_index', 'customer_seniority', 'primary_customer_index', 'last_date_primary_customer', \n",
    "              'customer_type', 'customer_relation_type', 'residence_index', 'foreign_index', 'spouse_index', \n",
    "              'customer_join_channel', 'deceased_index', 'address_type', 'province_code', 'province_name', \n",
    "              'activity_index', 'household_gross_income', 'segmentation', 'savings_account', 'gurantees', \n",
    "              'current_accounts', 'derivada_account', 'payroll_account', 'junior_account','mas_particular_account',\n",
    "              'particular_account', 'particular_plus_account', 'shortterm_deposits', 'mediumterm_deposits', \n",
    "              'longterm_deposits', 'online_account', 'funds', 'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', \n",
    "              'securities', 'home_account', 'payroll', 'pensions_2', 'direct_debit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>employee_index</th>\n",
       "      <th>customer_country</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>first_contract_date</th>\n",
       "      <th>new_customer_index</th>\n",
       "      <th>customer_seniority</th>\n",
       "      <th>primary_customer_index</th>\n",
       "      <th>...</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>pensions</th>\n",
       "      <th>loans</th>\n",
       "      <th>taxes</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>securities</th>\n",
       "      <th>home_account</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pensions_2</th>\n",
       "      <th>direct_debit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5444043</th>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>283524</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>45</td>\n",
       "      <td>2001-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989833</th>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>807725</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>30</td>\n",
       "      <td>2008-10-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900513</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>383639</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>46</td>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966928</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>137185</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>69</td>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171286</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>216607</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>44</td>\n",
       "      <td>2001-01-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  customer_code employee_index customer_country sex  age  \\\n",
       "5444043  2015-08-28         283524              N               ES   V   45   \n",
       "3989833  2015-07-28         807725              N               ES   H   30   \n",
       "900513   2015-02-28         383639              N               ES   V   46   \n",
       "6966928  2015-10-28         137185              N               ES   V   69   \n",
       "2171286  2015-04-28         216607              N               ES   V   44   \n",
       "\n",
       "        first_contract_date  new_customer_index customer_seniority  \\\n",
       "5444043          2001-10-17                 0.0                166   \n",
       "3989833          2008-10-22                 0.0                 81   \n",
       "900513           2002-09-30                 0.0                154   \n",
       "6966928          1999-06-30                 0.0                196   \n",
       "2171286          2001-01-19                 0.0                174   \n",
       "\n",
       "         primary_customer_index      ...      mortgage pensions loans taxes  \\\n",
       "5444043                     1.0      ...             0        0     0     0   \n",
       "3989833                     1.0      ...             0        0     0     0   \n",
       "900513                      1.0      ...             0        0     0     0   \n",
       "6966928                     1.0      ...             0        0     0     0   \n",
       "2171286                     1.0      ...             0        0     0     0   \n",
       "\n",
       "        credit_card securities home_account payroll  pensions_2  direct_debit  \n",
       "5444043           0          0            0     1.0         1.0             1  \n",
       "3989833           0          0            0     0.0         0.0             0  \n",
       "900513            0          0            0     0.0         0.0             0  \n",
       "6966928           0          1            0     0.0         0.0             0  \n",
       "2171286           0          0            0     0.0         0.0             0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observe what we have so far\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of rows\n",
    "df.customer_code.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have successfully changed the column names and limited our dataset to 1 million. Here is where the real data cleaning will begin.\n",
    "\n",
    "### Data Types\n",
    "\n",
    "I will begin by fixing the data types for various rows. Right now, everything is marked as an 'object' type. What we can do is change columns that contain integers with pd.to_numeric(). I'll start with some columns that clearly need to be marked as such.\n",
    "\n",
    "I also want to change the 'date' column to a datetime object. After that, I will create a new column 'month' that can help us find additional insights later on in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix data types\n",
    "df.age = pd.to_numeric(df.age, errors='coerce')\n",
    "df.date = pd.to_datetime(df.date, format=\"%Y-%m-%d\", errors='coerce')\n",
    "df.household_gross_income = pd.to_numeric(df.household_gross_income, errors='coerce')\n",
    "df.customer_seniority = pd.to_numeric(df.customer_seniority, errors=\"coerce\")\n",
    "df.first_contract_date = pd.to_datetime(df.first_contract_date, format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "#Create month column for possible insights\n",
    "df['month'] = pd.DatetimeIndex(df.date).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000000 entries, 5444043 to 1016900\n",
      "Data columns (total 49 columns):\n",
      "date                          1000000 non-null datetime64[ns]\n",
      "customer_code                 1000000 non-null int64\n",
      "employee_index                996089 non-null object\n",
      "customer_country              996089 non-null object\n",
      "sex                           996085 non-null object\n",
      "age                           996089 non-null float64\n",
      "first_contract_date           996089 non-null datetime64[ns]\n",
      "new_customer_index            996089 non-null float64\n",
      "customer_seniority            996089 non-null float64\n",
      "primary_customer_index        996089 non-null float64\n",
      "last_date_primary_customer    1522 non-null object\n",
      "customer_type                 985073 non-null object\n",
      "customer_relation_type        985073 non-null object\n",
      "residence_index               996089 non-null object\n",
      "foreign_index                 996089 non-null object\n",
      "spouse_index                  144 non-null object\n",
      "customer_join_channel         983015 non-null object\n",
      "deceased_index                996089 non-null object\n",
      "address_type                  996089 non-null float64\n",
      "province_code                 990939 non-null float64\n",
      "province_name                 990939 non-null object\n",
      "activity_index                996089 non-null float64\n",
      "household_gross_income        820856 non-null float64\n",
      "segmentation                  982857 non-null object\n",
      "savings_account               1000000 non-null int64\n",
      "gurantees                     1000000 non-null int64\n",
      "current_accounts              1000000 non-null int64\n",
      "derivada_account              1000000 non-null int64\n",
      "payroll_account               1000000 non-null int64\n",
      "junior_account                1000000 non-null int64\n",
      "mas_particular_account        1000000 non-null int64\n",
      "particular_account            1000000 non-null int64\n",
      "particular_plus_account       1000000 non-null int64\n",
      "shortterm_deposits            1000000 non-null int64\n",
      "mediumterm_deposits           1000000 non-null int64\n",
      "longterm_deposits             1000000 non-null int64\n",
      "online_account                1000000 non-null int64\n",
      "funds                         1000000 non-null int64\n",
      "mortgage                      1000000 non-null int64\n",
      "pensions                      1000000 non-null int64\n",
      "loans                         1000000 non-null int64\n",
      "taxes                         1000000 non-null int64\n",
      "credit_card                   1000000 non-null int64\n",
      "securities                    1000000 non-null int64\n",
      "home_account                  1000000 non-null int64\n",
      "payroll                       997699 non-null float64\n",
      "pensions_2                    997699 non-null float64\n",
      "direct_debit                  1000000 non-null int64\n",
      "month                         1000000 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(10), int64(24), object(13)\n",
      "memory usage: 381.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Confirm data types were fixed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "We need to get rid of all NaN values in the dataset. df.isnull().sum() will help us do that by giving us a frame of reference. I will refer back to that output from time to time to make sure all of the NaNs are taken care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                               0\n",
       "customer_code                      0\n",
       "employee_index                  3911\n",
       "customer_country                3911\n",
       "sex                             3915\n",
       "age                             3911\n",
       "first_contract_date             3911\n",
       "new_customer_index              3911\n",
       "customer_seniority              3911\n",
       "primary_customer_index          3911\n",
       "last_date_primary_customer    998478\n",
       "customer_type                  14927\n",
       "customer_relation_type         14927\n",
       "residence_index                 3911\n",
       "foreign_index                   3911\n",
       "spouse_index                  999856\n",
       "customer_join_channel          16985\n",
       "deceased_index                  3911\n",
       "address_type                    3911\n",
       "province_code                   9061\n",
       "province_name                   9061\n",
       "activity_index                  3911\n",
       "household_gross_income        179144\n",
       "segmentation                   17143\n",
       "savings_account                    0\n",
       "gurantees                          0\n",
       "current_accounts                   0\n",
       "derivada_account                   0\n",
       "payroll_account                    0\n",
       "junior_account                     0\n",
       "mas_particular_account             0\n",
       "particular_account                 0\n",
       "particular_plus_account            0\n",
       "shortterm_deposits                 0\n",
       "mediumterm_deposits                0\n",
       "longterm_deposits                  0\n",
       "online_account                     0\n",
       "funds                              0\n",
       "mortgage                           0\n",
       "pensions                           0\n",
       "loans                              0\n",
       "taxes                              0\n",
       "credit_card                        0\n",
       "securities                         0\n",
       "home_account                       0\n",
       "payroll                         2301\n",
       "pensions_2                      2301\n",
       "direct_debit                       0\n",
       "month                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See which columns have null values (And how many)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null rows in date and customer_code columns\n",
    "df = df.dropna(axis=0, subset=['date', 'customer_code'])\n",
    "\n",
    "#Drop columns with more than 50% null values\n",
    "df = df.drop(['last_date_primary_customer', 'spouse_index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change null values to median date\n",
    "dates=df.loc[:,\"first_contract_date\"].sort_values().reset_index()\n",
    "median_date = int(np.median(dates.index.values))\n",
    "df.loc[df.first_contract_date.isnull(),\"first_contract_date\"] = dates.loc[median_date,\"first_contract_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3911"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A lot of null values here\n",
    "df.new_customer_index.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see how 'new' these null customers are\n",
    "months_active = df.loc[df[\"new_customer_index\"].isnull(),:].groupby(\"customer_code\", sort=False).size()\n",
    "months_active.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mark as new customers\n",
    "df.loc[df.new_customer_index.isnull(), 'new_customer_index'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3911"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar number of null values as new_customer_index\n",
    "#Most likely same people\n",
    "df.customer_seniority.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will give them the minimum seniority since we know that\n",
    "#they are all new customers\n",
    "df.loc[df.customer_seniority.isnull(),\"customer_seniority\"] = df.customer_seniority.min()\n",
    "df.loc[df.customer_seniority <0, \"customer_seniority\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unneeded columns\n",
    "#We do not need address type\n",
    "#We do not need province_code because we have the name of each province in province_name\n",
    "df.drop([\"address_type\",\"province_code\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a pattern here. For a lot of the rows, I've noticed that there are around 6800 rows that have null values across a lot of the demographic columns. This tells me that these rows are almost the same ones and are likely filled with bad data. For the purposes of this project, I will go ahead and just drop all rows that have around 6800 null values in the demographic columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=['employee_index', 'customer_country', 'sex', 'age', 'primary_customer_index', \n",
    "                               'customer_type', 'customer_relation_type', 'residence_index', 'foreign_index', \n",
    "                               'customer_join_channel', 'deceased_index', 'activity_index', 'segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                            0\n",
       "customer_code                   0\n",
       "employee_index                  0\n",
       "customer_country                0\n",
       "sex                             0\n",
       "age                             0\n",
       "first_contract_date             0\n",
       "new_customer_index              0\n",
       "customer_seniority              0\n",
       "primary_customer_index          0\n",
       "customer_type                   0\n",
       "customer_relation_type          0\n",
       "residence_index                 0\n",
       "foreign_index                   0\n",
       "customer_join_channel           0\n",
       "deceased_index                  0\n",
       "province_name                5136\n",
       "activity_index                  0\n",
       "household_gross_income     168139\n",
       "segmentation                    0\n",
       "savings_account                 0\n",
       "gurantees                       0\n",
       "current_accounts                0\n",
       "derivada_account                0\n",
       "payroll_account                 0\n",
       "junior_account                  0\n",
       "mas_particular_account          0\n",
       "particular_account              0\n",
       "particular_plus_account         0\n",
       "shortterm_deposits              0\n",
       "mediumterm_deposits             0\n",
       "longterm_deposits               0\n",
       "online_account                  0\n",
       "funds                           0\n",
       "mortgage                        0\n",
       "pensions                        0\n",
       "loans                           0\n",
       "taxes                           0\n",
       "credit_card                     0\n",
       "securities                      0\n",
       "home_account                    0\n",
       "payroll                        15\n",
       "pensions_2                     15\n",
       "direct_debit                    0\n",
       "month                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our progress so far\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Each Column for Strange Values\n",
    "\n",
    "Now that we have taken care of most of the null values for the demographic data, I decided to take a look at the value counts for each individual column to see if there were any strange values included. I will now work on getting those strange values out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     981573\n",
       "99.0      1225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See what values we have for primary_customer_index\n",
    "pd.Series([i for i in df.primary_customer_index]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'primary_customer_index' column is a prime example of a column that includes bad data. There should only be two values here: 1 or 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numeric\n",
    "df.primary_customer_index = pd.to_numeric(df.primary_customer_index, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     981573\n",
       "99.0      1225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([i for i in df.primary_customer_index]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to numeric helped, but we still need to get rid of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 0 to most popular (1.0)\n",
    "df.loc[df.primary_customer_index <= 0, 'primary_customer_index'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     981573\n",
       "99.0      1225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm it worked\n",
    "pd.Series([i for i in df.primary_customer_index]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will take a look at the values for 'province_name'. Clearly there is some bad data in here that needs to be taken care of as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MADRID                    320201\n",
       "BARCELONA                  89881\n",
       "VALENCIA                   47428\n",
       "SEVILLA                    44680\n",
       "CORUÑA, A                  31688\n",
       "MURCIA                     28674\n",
       "MALAGA                     27513\n",
       "ZARAGOZA                   24703\n",
       "ALICANTE                   21913\n",
       "CADIZ                      21794\n",
       "PONTEVEDRA                 20283\n",
       "ASTURIAS                   18613\n",
       "VALLADOLID                 17318\n",
       "PALMAS, LAS                16847\n",
       "BADAJOZ                    14181\n",
       "BIZKAIA                    13453\n",
       "TOLEDO                     13286\n",
       "GRANADA                    12938\n",
       "SALAMANCA                  12042\n",
       "CANTABRIA                  11030\n",
       "CORDOBA                    10607\n",
       "CACERES                     9715\n",
       "HUELVA                      9383\n",
       "CIUDAD REAL                 8892\n",
       "BALEARS, ILLES              8398\n",
       "ALBACETE                    8114\n",
       "CASTELLON                   7664\n",
       "BURGOS                      6924\n",
       "GIRONA                      6430\n",
       "NAVARRA                     6404\n",
       "TARRAGONA                   6388\n",
       "LUGO                        6353\n",
       "OURENSE                     6218\n",
       "RIOJA, LA                   5923\n",
       "LEON                        5825\n",
       "LERIDA                      5676\n",
       "GIPUZKOA                    5133\n",
       "SANTA CRUZ DE TENERIFE      4986\n",
       "JAEN                        4617\n",
       "GUADALAJARA                 4336\n",
       "ALMERIA                     4311\n",
       "CUENCA                      4219\n",
       "ZAMORA                      3730\n",
       "PALENCIA                    3472\n",
       "SEGOVIA                     3042\n",
       "AVILA                       2829\n",
       "HUESCA                      2788\n",
       "ALAVA                       2780\n",
       "TERUEL                      1612\n",
       "SORIA                       1206\n",
       "MELILLA                      687\n",
       "CEUTA                        534\n",
       "Name: province_name, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.province_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MADRID         320201\n",
       "BARCELONA       89881\n",
       "VALENCIA        47428\n",
       "SEVILLA         44680\n",
       "MURCIA          28674\n",
       "MALAGA          27513\n",
       "ZARAGOZA        24703\n",
       "ALICANTE        21913\n",
       "CADIZ           21794\n",
       "PONTEVEDRA      20283\n",
       "ASTURIAS        18613\n",
       "VALLADOLID      17318\n",
       "BADAJOZ         14181\n",
       "BIZKAIA         13453\n",
       "TOLEDO          13286\n",
       "GRANADA         12938\n",
       "SALAMANCA       12042\n",
       "CANTABRIA       11030\n",
       "CORDOBA         10607\n",
       "CACERES          9715\n",
       "HUELVA           9383\n",
       "ALBACETE         8114\n",
       "CASTELLON        7664\n",
       "BURGOS           6924\n",
       "GIRONA           6430\n",
       "NAVARRA          6404\n",
       "TARRAGONA        6388\n",
       "LUGO             6353\n",
       "OURENSE          6218\n",
       "LEON             5825\n",
       "LERIDA           5676\n",
       "nan              5136\n",
       "GIPUZKOA         5133\n",
       "JAEN             4617\n",
       "GUADALAJARA      4336\n",
       "ALMERIA          4311\n",
       "CUENCA           4219\n",
       "ZAMORA           3730\n",
       "PALENCIA         3472\n",
       "SEGOVIA          3042\n",
       "AVILA            2829\n",
       "HUESCA           2788\n",
       "ALAVA            2780\n",
       "TERUEL           1612\n",
       "SORIA            1206\n",
       "MELILLA           687\n",
       "CEUTA             534\n",
       "Name: province_name, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change type to string\n",
    "df.province_name = df.province_name.astype(str)\n",
    "\n",
    "#Drop null values\n",
    "df = df.dropna(axis=0, subset=['province_name'])\n",
    "\n",
    "#Create a subset that includes rows that contain only alphabetic characters\n",
    "subset = df.province_name.str.isalpha()\n",
    "\n",
    "#Update the dataframe to include the subset\n",
    "df = df[subset]\n",
    "\n",
    "#Check to make sure everything worked\n",
    "df.province_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be two values that don't need to be there: 'nan' and 'VRCIA'. I will drop those from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop bad values\n",
    "df = df[df.province_name != 'nan']\n",
    "df = df[df.province_name != 'VRCIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MADRID         320201\n",
       "BARCELONA       89881\n",
       "VALENCIA        47428\n",
       "SEVILLA         44680\n",
       "MURCIA          28674\n",
       "MALAGA          27513\n",
       "ZARAGOZA        24703\n",
       "ALICANTE        21913\n",
       "CADIZ           21794\n",
       "PONTEVEDRA      20283\n",
       "ASTURIAS        18613\n",
       "VALLADOLID      17318\n",
       "BADAJOZ         14181\n",
       "BIZKAIA         13453\n",
       "TOLEDO          13286\n",
       "GRANADA         12938\n",
       "SALAMANCA       12042\n",
       "CANTABRIA       11030\n",
       "CORDOBA         10607\n",
       "CACERES          9715\n",
       "HUELVA           9383\n",
       "ALBACETE         8114\n",
       "CASTELLON        7664\n",
       "BURGOS           6924\n",
       "GIRONA           6430\n",
       "NAVARRA          6404\n",
       "TARRAGONA        6388\n",
       "LUGO             6353\n",
       "OURENSE          6218\n",
       "LEON             5825\n",
       "LERIDA           5676\n",
       "GIPUZKOA         5133\n",
       "JAEN             4617\n",
       "GUADALAJARA      4336\n",
       "ALMERIA          4311\n",
       "CUENCA           4219\n",
       "ZAMORA           3730\n",
       "PALENCIA         3472\n",
       "SEGOVIA          3042\n",
       "AVILA            2829\n",
       "HUESCA           2788\n",
       "ALAVA            2780\n",
       "TERUEL           1612\n",
       "SORIA            1206\n",
       "MELILLA           687\n",
       "CEUTA             534\n",
       "Name: province_name, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that it worked\n",
    "df.province_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                            0\n",
       "customer_code                   0\n",
       "employee_index                  0\n",
       "customer_country                0\n",
       "sex                             0\n",
       "age                             0\n",
       "first_contract_date             0\n",
       "new_customer_index              0\n",
       "customer_seniority              0\n",
       "primary_customer_index          0\n",
       "customer_type                   0\n",
       "customer_relation_type          0\n",
       "residence_index                 0\n",
       "foreign_index                   0\n",
       "customer_join_channel           0\n",
       "deceased_index                  0\n",
       "province_name                   0\n",
       "activity_index                  0\n",
       "household_gross_income     145214\n",
       "segmentation                    0\n",
       "savings_account                 0\n",
       "gurantees                       0\n",
       "current_accounts                0\n",
       "derivada_account                0\n",
       "payroll_account                 0\n",
       "junior_account                  0\n",
       "mas_particular_account          0\n",
       "particular_account              0\n",
       "particular_plus_account         0\n",
       "shortterm_deposits              0\n",
       "mediumterm_deposits             0\n",
       "longterm_deposits               0\n",
       "online_account                  0\n",
       "funds                           0\n",
       "mortgage                        0\n",
       "pensions                        0\n",
       "loans                           0\n",
       "taxes                           0\n",
       "credit_card                     0\n",
       "securities                      0\n",
       "home_account                    0\n",
       "payroll                        15\n",
       "pensions_2                     15\n",
       "direct_debit                    0\n",
       "month                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Switching gears back to null values, let's get another progress report\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next on our list is fixing 'household_gross_income'. It contains a lot of null values, but instead of just changing them to the median of the entire column, I want to change those null values to the median for each 'province_name'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:4291: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>province_name</th>\n",
       "      <th>household_gross_income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MedianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BADAJOZ</td>\n",
       "      <td>62142.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUGO</td>\n",
       "      <td>63755.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LERIDA</td>\n",
       "      <td>64481.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASTELLON</td>\n",
       "      <td>66630.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALICANTE</td>\n",
       "      <td>67420.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province_name household_gross_income\n",
       "                          MedianIncome\n",
       "0       BADAJOZ               62142.54\n",
       "1          LUGO               63755.73\n",
       "2        LERIDA               64481.91\n",
       "3     CASTELLON               66630.30\n",
       "4      ALICANTE               67420.11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group 'household_gross_income' by 'province_name' and get the median income\n",
    "incomes = df.loc[df.household_gross_income.notnull(),:].groupby(\"province_name\").agg({\"household_gross_income\":{\"MedianIncome\":np.median}})\n",
    "\n",
    "#Sort\n",
    "incomes.sort_values(by=(\"household_gross_income\",\"MedianIncome\"),inplace=True)\n",
    "\n",
    "#Reset index\n",
    "incomes.reset_index(inplace=True)\n",
    "\n",
    "#Change type\n",
    "incomes.province_name = incomes.province_name.astype(\"category\", categories=[i for i in df.province_name.unique()],ordered=False)\n",
    "\n",
    "#Observe results\n",
    "incomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 'province_name' by 'household_gross_income' and get the median\n",
    "grouped = df.groupby(\"province_name\").agg({\"household_gross_income\":lambda x: x.median(skipna=True)}).reset_index()\n",
    "\n",
    "#Merge our main dataframe and the grouped dataframe\n",
    "new_incomes = pd.merge(df,grouped,how=\"inner\",on=\"province_name\").loc[:, [\"province_name\",\"household_gross_income_y\"]]\n",
    "\n",
    "#Rename columns\n",
    "new_incomes = new_incomes.rename(columns={\"household_gross_income_y\":\"household_gross_income\"}).sort_values(\"household_gross_income\").sort_values(\"province_name\")\n",
    "\n",
    "#Sort\n",
    "df.sort_values(\"province_name\",inplace=True)\n",
    "\n",
    "#Reset index\n",
    "df = df.reset_index()\n",
    "new_incomes = new_incomes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, change null values to reflect median income by 'province_name'\n",
    "df.loc[df.household_gross_income.isnull(),\"household_gross_income\"] = new_incomes.loc[df.household_gross_income.isnull(),\"household_gross_income\"].reset_index()\n",
    "df.loc[df.household_gross_income.isnull(),\"household_gross_income\"] = df.loc[df.household_gross_income.notnull(),\"household_gross_income\"].median()\n",
    "df.sort_values(by=\"date\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       0\n",
       "date                        0\n",
       "customer_code               0\n",
       "employee_index              0\n",
       "customer_country            0\n",
       "sex                         0\n",
       "age                         0\n",
       "first_contract_date         0\n",
       "new_customer_index          0\n",
       "customer_seniority          0\n",
       "primary_customer_index      0\n",
       "customer_type               0\n",
       "customer_relation_type      0\n",
       "residence_index             0\n",
       "foreign_index               0\n",
       "customer_join_channel       0\n",
       "deceased_index              0\n",
       "province_name               0\n",
       "activity_index              0\n",
       "household_gross_income      0\n",
       "segmentation                0\n",
       "savings_account             0\n",
       "gurantees                   0\n",
       "current_accounts            0\n",
       "derivada_account            0\n",
       "payroll_account             0\n",
       "junior_account              0\n",
       "mas_particular_account      0\n",
       "particular_account          0\n",
       "particular_plus_account     0\n",
       "shortterm_deposits          0\n",
       "mediumterm_deposits         0\n",
       "longterm_deposits           0\n",
       "online_account              0\n",
       "funds                       0\n",
       "mortgage                    0\n",
       "pensions                    0\n",
       "loans                       0\n",
       "taxes                       0\n",
       "credit_card                 0\n",
       "securities                  0\n",
       "home_account                0\n",
       "payroll                    15\n",
       "pensions_2                 15\n",
       "direct_debit                0\n",
       "month                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting closer\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! At this point, the rest of the null values are in the 'product' columns. Since there are very few of them(In the grand scheme of our 900k+ dataset), I will go ahead and change those null values to 0, which indicates that the customer has not bought the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change remaining null values to 0\n",
    "df.loc[df.payroll_account.isnull(), \"payroll_account\"] = 0\n",
    "df.loc[df.junior_account.isnull(), \"junior_account\"] = 0\n",
    "df.loc[df.mas_particular_account.isnull(), \"mas_particular_account\"] = 0\n",
    "df.loc[df.particular_account.isnull(), \"particular_account\"] = 0\n",
    "df.loc[df.particular_plus_account.isnull(), \"particular_plus_account\"] = 0\n",
    "df.loc[df.shortterm_deposits.isnull(), \"shortterm_deposits\"] = 0\n",
    "df.loc[df.mediumterm_deposits.isnull(), \"mediumterm_deposits\"] = 0\n",
    "df.loc[df.longterm_deposits.isnull(), \"longterm_deposits\"] = 0\n",
    "df.loc[df.online_account.isnull(), \"online_account\"] = 0\n",
    "df.loc[df.funds.isnull(), \"funds\"] = 0\n",
    "df.loc[df.mortgage.isnull(), \"mortgage\"] = 0\n",
    "df.loc[df.pensions.isnull(), \"pensions\"] = 0\n",
    "df.loc[df.loans.isnull(), \"loans\"] = 0\n",
    "df.loc[df.taxes.isnull(), \"taxes\"] = 0\n",
    "df.loc[df.credit_card.isnull(), \"credit_card\"] = 0\n",
    "df.loc[df.securities.isnull(), \"securities\"] = 0\n",
    "df.loc[df.home_account.isnull(), \"home_account\"] = 0\n",
    "df.loc[df.payroll.isnull(), \"payroll\"] = 0\n",
    "df.loc[df.pensions_2.isnull(), \"pensions_2\"] = 0\n",
    "df.loc[df.direct_debit.isnull(), \"direct_debit\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                      0\n",
       "date                       0\n",
       "customer_code              0\n",
       "employee_index             0\n",
       "customer_country           0\n",
       "sex                        0\n",
       "age                        0\n",
       "first_contract_date        0\n",
       "new_customer_index         0\n",
       "customer_seniority         0\n",
       "primary_customer_index     0\n",
       "customer_type              0\n",
       "customer_relation_type     0\n",
       "residence_index            0\n",
       "foreign_index              0\n",
       "customer_join_channel      0\n",
       "deceased_index             0\n",
       "province_name              0\n",
       "activity_index             0\n",
       "household_gross_income     0\n",
       "segmentation               0\n",
       "savings_account            0\n",
       "gurantees                  0\n",
       "current_accounts           0\n",
       "derivada_account           0\n",
       "payroll_account            0\n",
       "junior_account             0\n",
       "mas_particular_account     0\n",
       "particular_account         0\n",
       "particular_plus_account    0\n",
       "shortterm_deposits         0\n",
       "mediumterm_deposits        0\n",
       "longterm_deposits          0\n",
       "online_account             0\n",
       "funds                      0\n",
       "mortgage                   0\n",
       "pensions                   0\n",
       "loans                      0\n",
       "taxes                      0\n",
       "credit_card                0\n",
       "securities                 0\n",
       "home_account               0\n",
       "payroll                    0\n",
       "pensions_2                 0\n",
       "direct_debit               0\n",
       "month                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finally gotten rid of all null values, we need to make sure that the unique values for each column are correct and that no bad data is present. I went ahead and checked each column individually. Below are the ones that include data that needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    876398\n",
       "1.0     24530\n",
       "Name: new_customer_index, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check values for 'new_customer_index\n",
    "df.new_customer_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change values to numeric\n",
    "df.new_customer_index = pd.to_numeric(df.new_customer_index, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    876398\n",
       "1.0     24530\n",
       "Name: new_customer_index, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that it worked\n",
    "df.new_customer_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    900923\n",
       "3.0         5\n",
       "Name: customer_type, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change 'customer_type' to numeric and make sure that it worked\n",
    "df.customer_type = pd.to_numeric(df.customer_type, errors='coerce')\n",
    "df.customer_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    456322\n",
       "1.0    444606\n",
       "Name: activity_index, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do the same thing for 'activity_index'\n",
    "df.activity_index = pd.to_numeric(df.activity_index, errors='coerce')\n",
    "df.activity_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02 - PARTICULARES     538804\n",
       "03 - UNIVERSITARIO    319592\n",
       "01 - TOP               42532\n",
       "Name: segmentation, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check unique values for 'segmentation'\n",
    "df.segmentation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02 - PARTICULARES     538804\n",
       "03 - UNIVERSITARIO    319592\n",
       "01 - TOP               42532\n",
       "Name: segmentation, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make bad values null, check to make sure it worked\n",
    "df.loc[df.segmentation == '0', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '03 - UNIV0', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '02 - PART- UNIVERSITARIO', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '03 - UNIVERSIT0', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '03 - UNIVERSITARTICULARES', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '02 - PARTI', 'segmentation'] = np.nan\n",
    "df.loc[df.segmentation == '02 - PARTICULAIO', 'segmentation'] = np.nan\n",
    "df.segmentation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values \n",
    "df = df.dropna(axis=0, subset=['segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    900248\n",
       "B       276\n",
       "A       205\n",
       "F       198\n",
       "S         1\n",
       "Name: employee_index, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'S' should not be included in 'employee_index'\n",
    "df.employee_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    900249\n",
       "B       276\n",
       "A       205\n",
       "F       198\n",
       "Name: employee_index, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change 'S' to most popular ('N') for 'employee_index' and make sure it worked\n",
    "df.loc[df.employee_index == 'S', 'employee_index'] = 'N'\n",
    "df.employee_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763098\n",
       "1    137830\n",
       "Name: particular_account, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert 'particular_account' to numeric and confirm that it worked\n",
    "df.particular_account = pd.to_numeric(df.particular_account, errors='coerce')\n",
    "df.particular_account.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same thing for 'longterm_deposits'\n",
    "df.longterm_deposits = pd.to_numeric(df.longterm_deposits, errors='coerce')\n",
    "df.longterm_deposits.value_counts()\n",
    "\n",
    "#Drop null values\n",
    "df = df.dropna(axis=0, subset=['longterm_deposits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    817134\n",
       "1     83794\n",
       "Name: online_account, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And do the same thing for 'online_account'\n",
    "df.online_account = pd.to_numeric(df.online_account, errors='coerce')\n",
    "df.online_account.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally finished cleaning the data! Now there's just one last step. In order to properly identify customer purchasing trends within the data, we need to create a label for each product and unique month that indicates whether a customer added, dropped or maintained a product that specific billing cycle. We will do this by assigning a numeric ID to each unique time stamp and then match each entry with the one from the previous month. The difference in the indicator value for each will give us the desired value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we begin, we need to make the feature columns (products the bank offers) integer values\n",
    "feature_cols = df.iloc[:, 21:-1].columns.values\n",
    "for col in feature_cols:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variable for unique months\n",
    "unique_months = pd.DataFrame(pd.Series(df.date.unique()).sort_values()).reset_index(drop=True)\n",
    "\n",
    "# start with month 1, not 0 to match what we already have\n",
    "unique_months[\"month_id\"] = pd.Series(range(1,1+unique_months.size)) \n",
    "\n",
    "unique_months[\"month_next_id\"] = 1 + unique_months[\"month_id\"]\n",
    "\n",
    "unique_months.rename(columns={0:\"date\"},inplace=True)\n",
    "\n",
    "#Merge df with unique_months\n",
    "df = pd.merge(df,unique_months,on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for labelling each product as 'Added', 'Dropped' or 'Maintained'\n",
    "def status_change(x):\n",
    "    diffs = x.diff().fillna(0)\n",
    "    label = [\"Added\" if i==1 \\\n",
    "         else \"Dropped\" if i==-1 \\\n",
    "         else \"Maintained\" for i in diffs]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function\n",
    "df.loc[:, feature_cols] = df.loc[:, [i for i in feature_cols]+[\"customer_code\"]].groupby(\"customer_code\").transform(status_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55901, 26)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since we are only interested in seeing instances of customers adding or dropping products,\n",
    "#we will get rid of any instance in which a customer 'Maintained' a product\n",
    "df = pd.melt(df, id_vars=[col for col in df.columns if col not in feature_cols],\n",
    "            value_vars=[col for col in feature_cols])\n",
    "df = df.loc[df.value!=\"Maintained\",:]\n",
    "\n",
    "#What does our dataframe look like now?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>employee_index</th>\n",
       "      <th>customer_country</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>first_contract_date</th>\n",
       "      <th>new_customer_index</th>\n",
       "      <th>customer_seniority</th>\n",
       "      <th>...</th>\n",
       "      <th>deceased_index</th>\n",
       "      <th>province_name</th>\n",
       "      <th>activity_index</th>\n",
       "      <th>household_gross_income</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>month</th>\n",
       "      <th>month_id</th>\n",
       "      <th>month_next_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699700</th>\n",
       "      <td>4827636</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>423998</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2003-06-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74259.78</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>savings_account</td>\n",
       "      <td>Dropped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563725</th>\n",
       "      <td>5347832</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>89574</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1998-03-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233735.55</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>gurantees</td>\n",
       "      <td>Dropped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883609</th>\n",
       "      <td>1103787</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>984406</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2011-11-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45329.46</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>current_accounts</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884087</th>\n",
       "      <td>879806</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>343743</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2002-03-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140839.83</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>current_accounts</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884480</th>\n",
       "      <td>1030418</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1322454</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-10-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74630.19</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>current_accounts</td>\n",
       "      <td>Dropped</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index       date  customer_code employee_index customer_country  \\\n",
       "699700   4827636 2015-08-28         423998              N               ES   \n",
       "1563725  5347832 2015-08-28          89574              N               ES   \n",
       "1883609  1103787 2015-02-28         984406              N               ES   \n",
       "1884087   879806 2015-02-28         343743              N               ES   \n",
       "1884480  1030418 2015-02-28        1322454              N               ES   \n",
       "\n",
       "        sex   age first_contract_date  new_customer_index  customer_seniority  \\\n",
       "699700    V  39.0          2003-06-19                 0.0               146.0   \n",
       "1563725   V  38.0          1998-03-16                 0.0               209.0   \n",
       "1883609   V  25.0          2011-11-23                 0.0                44.0   \n",
       "1884087   H  59.0          2002-03-18                 0.0               160.0   \n",
       "1884480   H  22.0          2014-10-03                 0.0                10.0   \n",
       "\n",
       "          ...     deceased_index  province_name activity_index  \\\n",
       "699700    ...                  N         MADRID            1.0   \n",
       "1563725   ...                  N         MADRID            1.0   \n",
       "1883609   ...                  N         MADRID            1.0   \n",
       "1884087   ...                  N         MADRID            1.0   \n",
       "1884480   ...                  N         MADRID            1.0   \n",
       "\n",
       "        household_gross_income        segmentation month month_id  \\\n",
       "699700                74259.78            01 - TOP     8        8   \n",
       "1563725              233735.55   02 - PARTICULARES     8        8   \n",
       "1883609               45329.46  03 - UNIVERSITARIO     2        2   \n",
       "1884087              140839.83            01 - TOP     2        2   \n",
       "1884480               74630.19  03 - UNIVERSITARIO     2        2   \n",
       "\n",
       "        month_next_id          variable    value  \n",
       "699700              9   savings_account  Dropped  \n",
       "1563725             9         gurantees  Dropped  \n",
       "1883609             3  current_accounts    Added  \n",
       "1884087             3  current_accounts    Added  \n",
       "1884480             3  current_accounts  Dropped  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe to csv\n",
    "df.to_csv(\"Data/train_ver2_CLEAN\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally finished with this portion of the project! Now that we have the data clean and tidy, we can move on toward performing some exploratory data analysis, which is what I will primarily focus on in the next notebok."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
